{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ü§ñ .NET Interactive Notebook: Hybrid RAG with OpenAI Integration\n",
    "\n",
    "**Language**: C# (.NET 7+ with .NET Interactive kernel)\n",
    "\n",
    "### Features:\n",
    "- Document loading and preprocessing\n",
    "- Tokenization and chunking\n",
    "- Semantic embedding via OpenAI API\n",
    "- BM25 sparse search with Lucene.NET\n",
    "- Hybrid scoring + query handling\n",
    "- Final RAG response using OpenAI LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "csharp"
   },
   "outputs": [],
   "source": [
    "// Load required packages\n",
    "#r \"nuget:Lucene.Net, 4.8.0-beta00016\"\n",
    "#r \"nuget:Lucene.Net.Analysis.Common, 4.8.0-beta00016\"\n",
    "#r \"nuget:Newtonsoft.Json\"\n",
    "#r \"nuget:Microsoft.ML\"\n",
    "#r \"nuget:System.Net.Http.Json\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìÑ Load and Chunk Text Document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "csharp"
   },
   "outputs": [],
   "source": [
    "using System.Text;\n",
    "using System.Net.Http;\n",
    "using Newtonsoft.Json;\n",
    "\n",
    "string LoadTextFile(string path)\n",
    "{\n",
    "    return File.ReadAllText(path);\n",
    "}\n",
    "\n",
    "List<string> ChunkText(string content, int maxTokens = 200)\n",
    "{\n",
    "    var sentences = content.Split(new[] { \".\", \"\\n\" }, StringSplitOptions.RemoveEmptyEntries);\n",
    "    var chunks = new List<string>();\n",
    "    var sb = new StringBuilder();\n",
    "    foreach (var sentence in sentences)\n",
    "    {\n",
    "        sb.Append(sentence.Trim() + \". \");\n",
    "        if (sb.Length >= maxTokens * 4) // rough estimate\n",
    "        {\n",
    "            chunks.Add(sb.ToString().Trim());\n",
    "            sb.Clear();\n",
    "        }\n",
    "    }\n",
    "    if (sb.Length > 0) chunks.Add(sb.ToString().Trim());\n",
    "    return chunks;\n",
    "}\n",
    "\n",
    "var content = LoadTextFile(\"data/sample.txt\");\n",
    "var chunks = ChunkText(content);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üß† Generate Embeddings using OpenAI API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "csharp"
   },
   "outputs": [],
   "source": [
    "record OpenAIEmbeddingRequest(string model, List<string> input);\n",
    "record OpenAIEmbeddingResponse(List<EmbeddingData> data);\n",
    "record EmbeddingData(int index, List<float> embedding);\n",
    "\n",
    "async Task<List<List<float>>> GetEmbeddings(List<string> texts, string apiKey)\n",
    "{\n",
    "    using var client = new HttpClient();\n",
    "    client.DefaultRequestHeaders.Add(\"Authorization\", $\"Bearer {apiKey}\");\n",
    "    var request = new OpenAIEmbeddingRequest(\"text-embedding-ada-002\", texts);\n",
    "    var response = await client.PostAsJsonAsync(\"https://api.openai.com/v1/embeddings\", request);\n",
    "    var result = await response.Content.ReadFromJsonAsync<OpenAIEmbeddingResponse>();\n",
    "    return result.data.Select(d => d.embedding).ToList();\n",
    "}\n",
    "\n",
    "var apiKey = Environment.GetEnvironmentVariable(\"OPENAI_API_KEY\");\n",
    "var embeddings = await GetEmbeddings(chunks, apiKey);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîç Setup Lucene BM25 Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "csharp"
   },
   "outputs": [],
   "source": [
    "using Lucene.Net.Store;\n",
    "using Lucene.Net.Index;\n",
    "using Lucene.Net.Documents;\n",
    "using Lucene.Net.Analysis.Standard;\n",
    "using Lucene.Net.Search;\n",
    "using Lucene.Net.QueryParsers.Classic;\n",
    "\n",
    "var dir = new RAMDirectory();\n",
    "var analyzer = new StandardAnalyzer(Lucene.Net.Util.LuceneVersion.LUCENE_48);\n",
    "var config = new IndexWriterConfig(Lucene.Net.Util.LuceneVersion.LUCENE_48, analyzer);\n",
    "var writer = new IndexWriter(dir, config);\n",
    "\n",
    "for (int i = 0; i < chunks.Count; i++)\n",
    "{\n",
    "    var doc = new Document\n",
    "    {\n",
    "        new TextField(\"content\", chunks[i], Field.Store.YES),\n",
    "        new StringField(\"id\", i.ToString(), Field.Store.YES)\n",
    "    };\n",
    "    writer.AddDocument(doc);\n",
    "}\n",
    "writer.Commit();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîÄ Hybrid Search: BM25 + Vector Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "csharp"
   },
   "outputs": [],
   "source": [
    "double CosineSim(List<float> v1, List<float> v2)\n",
    "{\n",
    "    double dot = 0, mag1 = 0, mag2 = 0;\n",
    "    for (int i = 0; i < v1.Count; i++)\n",
    "    {\n",
    "        dot += v1[i] * v2[i];\n",
    "        mag1 += v1[i] * v1[i];\n",
    "        mag2 += v2[i] * v2[i];\n",
    "    }\n",
    "    return dot / (Math.Sqrt(mag1) * Math.Sqrt(mag2) + 1e-8);\n",
    "}\n",
    "\n",
    "async Task<List<string>> HybridSearch(string query, int k = 5)\n",
    "{\n",
    "    var reader = DirectoryReader.Open(dir);\n",
    "    var searcher = new IndexSearcher(reader);\n",
    "    var parser = new QueryParser(Lucene.Net.Util.LuceneVersion.LUCENE_48, \"content\", analyzer);\n",
    "    var luceneQuery = parser.Parse(QueryParser.Escape(query));\n",
    "    var hits = searcher.Search(luceneQuery, 10).ScoreDocs;\n",
    "\n",
    "    var qEmbed = (await GetEmbeddings(new List<string> { query }, apiKey))[0];\n",
    "    var scored = hits.Select(h =>\n",
    "    {\n",
    "        var doc = searcher.Doc(h.Doc);\n",
    "        var idx = int.Parse(doc.Get(\"id\"));\n",
    "        var score = CosineSim(qEmbed, embeddings[idx]);\n",
    "        return (chunk: chunks[idx], score);\n",
    "    }).OrderByDescending(x => x.score).Take(k).ToList();\n",
    "    return scored.Select(x => x.chunk).ToList();\n",
    "}\n",
    "\n",
    "// var results = await HybridSearch(\"licensing requirements\");\n",
    "// results.ForEach(r => Console.WriteLine(\"---\\n\" + r));"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
