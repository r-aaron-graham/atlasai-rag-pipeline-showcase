{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üåê Real-Time RAG Web Frontend via Blazor + Backend via Jupyter C#\n",
    "\n",
    "This notebook provides code and architecture guidance for integrating:\n",
    "- **Backend in .NET Interactive (C#)** using OpenAI + Lucene.NET\n",
    "- **Frontend in Blazor WebAssembly or Server** for real-time user interaction\n",
    "\n",
    "This hybrid RAG pipeline returns responses based on user queries using OpenAI embeddings + BM25.\n",
    "\n",
    "‚úÖ You will build:\n",
    "- A Web API backend (Blazor Server)\n",
    "- An embedded RAG inference endpoint\n",
    "- Frontend UI to submit questions and render answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "csharp"
   },
   "outputs": [],
   "source": [
    "// Backend API Controller for RAG Query\n",
    "using Microsoft.AspNetCore.Mvc;\n",
    "[ApiController]\n",
    "[Route(\"api/[controller]\")]\n",
    "public class RagController : ControllerBase\n",
    "{\n",
    "    [HttpPost(\"query\")]\n",
    "    public async Task<IActionResult> Query([FromBody] QueryRequest request)\n",
    "    {\n",
    "        var chunks = await HybridSearch(request.Question);\n",
    "        var prompt = $\"Answer the following using context:\\n{string.Join(\"\\n---\\n\", chunks)}\\n\\nQ: {request.Question}\\nA:\";\n",
    "        var response = await CallOpenAI(prompt);\n",
    "        return Ok(new { answer = response });\n",
    "    }\n",
    "    public record QueryRequest(string Question);\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üñ•Ô∏è Blazor Web UI (Pages/Rag.razor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@page \"/rag\"\n",
    "<h3>Ask RAG AI</h3>\n",
    "\n",
    "<input @bind=\"question\" placeholder=\"Ask a question\" class=\"form-control\" />\n",
    "<button class=\"btn btn-primary mt-2\" @onclick=\"SendQuery\">Ask</button>\n",
    "\n",
    "@if (answer != null)\n",
    "{\n",
    "    <div class=\"alert alert-info mt-3\">\n",
    "        <b>Answer:</b> @answer\n",
    "    </div>\n",
    "}\n",
    "\n",
    "@code {\n",
    "    string question;\n",
    "    string answer;\n",
    "\n",
    "    async Task SendQuery()\n",
    "    {\n",
    "        var request = new { question = question };\n",
    "        var http = new HttpClient();\n",
    "        var resp = await http.PostAsJsonAsync(\"/api/rag/query\", request);\n",
    "        var result = await resp.Content.ReadFromJsonAsync<JsonElement>();\n",
    "        answer = result.GetProperty(\"answer\").GetString();\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîß Integration Notes\n",
    "- Run the RAG pipeline service in .NET (with `Program.cs` for Web API hosting)\n",
    "- OpenAI key via `IConfiguration`\n",
    "- You can expand to stream token-by-token using OpenAI chat streaming and SignalR\n",
    "\n",
    "To deploy:\n",
    "1. `dotnet new blazorserver -o RAGWeb`\n",
    "2. Add API controller and Razor page above\n",
    "3. Inject backend logic via service interface or shared project\n",
    "4. Run with `dotnet run`\n",
    "\n",
    "**Optionally**, host API separately and call it from **Streamlit** or JS frontend with `fetch()`"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
